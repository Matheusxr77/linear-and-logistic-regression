import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.metrics import mean_squared_error, r2_score
from src.models import train_linear_regression
from src.plotting import (
    plot_regression_scatter,
    plot_predicted_vs_actual,
    plot_regression_confidence_interval,
    plot_regression_confusion_matrix
)

st.set_page_config(page_title="RegressÃ£o Linear", layout="wide")

st.title("Parte 1: AnÃ¡lise de RegressÃ£o Linear")
st.markdown("""
Nesta seÃ§Ã£o, utilizamos a RegressÃ£o Linear MÃºltipla para modelar a relaÃ§Ã£o entre uma variÃ¡vel de desempenho (dependente) e uma ou mais variÃ¡veis estatÃ­sticas (independentes).

**EquaÃ§Ã£o da RegressÃ£o Linear:**
""")

st.latex(r"y = \beta_0 + \beta_1x_1 + \beta_2x_2 + ... + \beta_nx_n + \varepsilon")

st.markdown("""
**HipÃ³teses que podemos testar:**
- Um determinado Jogador farÃ¡ Y pontos?
- Um determinado Jogador farÃ¡ Y rebotes?
- Um determinado Jogador farÃ¡ Y assistÃªncias?
- O time farÃ¡ X Pontos no jogo?
- O time farÃ¡ X Rebotes no jogo?
- O time farÃ¡ X AssistÃªncias no jogo?

**InstruÃ§Ãµes:**
1.  **Escolha a VariÃ¡vel Dependente (Y):** Selecione a estatÃ­stica que vocÃª deseja prever.
2.  **Escolha as VariÃ¡veis Independentes (X):** Selecione uma ou mais estatÃ­sticas que vocÃª acredita que influenciam a variÃ¡vel dependente.
3.  Clique em **'Executar AnÃ¡lise'** para treinar o modelo e visualizar os resultados.
""")

# Verifica se os dados foram carregados e estÃ£o no estado da sessÃ£o
if 'team_data' not in st.session_state or st.session_state['team_data'].empty:
    st.error("Os dados nÃ£o foram carregados. Por favor, volte para a pÃ¡gina principal (app.py) para iniciar o carregamento.")
else:
    df = st.session_state['team_data']

    # Define as colunas numÃ©ricas que podem ser usadas como variÃ¡veis
    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
    # Remove a variÃ¡vel 'WIN' que Ã© categÃ³rica por natureza
    if 'WIN' in numeric_cols:
        numeric_cols.remove('WIN')

    # --- Abas de NavegaÃ§Ã£o ---
    tabs = st.tabs(["ðŸ“Š AnÃ¡lise Principal", "ðŸ“ˆ ExploraÃ§Ã£o de Dados", "ðŸŽ AnÃ¡lise de ResÃ­duos"])

    # ============================================================================
    # ABA 1: ANÃLISE PRINCIPAL
    # ============================================================================
    with tabs[0]:
        st.subheader("Modelo de RegressÃ£o Linear")

        col1, col2 = st.columns(2)
        with col1:
            dependent_var = st.selectbox(
                "1. Escolha a VariÃ¡vel Dependente (Y) para prever:",
                options=numeric_cols,
                index=numeric_cols.index('PTS') if 'PTS' in numeric_cols else 0,
                help="Esta Ã© a variÃ¡vel que o modelo tentarÃ¡ prever."
            )

        available_independent_vars = [v for v in numeric_cols if v != dependent_var]

        with col2:
            independent_vars = st.multiselect(
                "2. Escolha as VariÃ¡veis Independentes (X):",
                options=available_independent_vars,
                default=[available_independent_vars[0]] if available_independent_vars else [],
                help="Estas sÃ£o as variÃ¡veis que o modelo usarÃ¡ para fazer a previsÃ£o."
            )

        if st.button("Executar AnÃ¡lise de RegressÃ£o Linear", type="primary"):
            if not independent_vars:
                st.warning("Por favor, selecione pelo menos uma variÃ¡vel independente.")
            else:
                with st.spinner("Treinando o modelo de RegressÃ£o Linear e gerando grÃ¡ficos..."):
                    results = train_linear_regression(df, independent_vars, dependent_var)

                    st.success("AnÃ¡lise concluÃ­da!")

                    # --- SeÃ§Ã£o de Resultados ---
                    st.subheader("Resultados do Modelo")

                    # Exibe a equaÃ§Ã£o da regressÃ£o
                    coef_str = " + ".join([f"({results['coefficients'].loc[var, 'Coefficient']:.4f} Ã— {var})" for var in independent_vars])
                    st.markdown("**EquaÃ§Ã£o de RegressÃ£o Ajustada:**")
                    st.latex(f"{dependent_var} = {results['intercept']:.4f} + {coef_str} + \\varepsilon")

                    # Exibe mÃ©tricas e coeficientes
                    col_metric1, col_metric2, col_metric3 = st.columns(3)
                    col_metric1.metric(label="Coeficiente de DeterminaÃ§Ã£o (RÂ²)", value=f"{results['r2']:.4f}",
                                      help="Quanto da variaÃ§Ã£o em Y Ã© explicada por X. Varia de 0 a 1.")
                    col_metric2.metric(label="Erro QuadrÃ¡tico MÃ©dio (MSE)", value=f"{results['mse']:.4f}",
                                      help="MÃ©dia dos erros ao quadrado. Quanto menor, melhor.")
                    col_metric3.metric(label="Raiz do MSE (RMSE)", value=f"{np.sqrt(results['mse']):.4f}",
                                      help="Erro mÃ©dio em unidades da variÃ¡vel Y.")

                    st.write("**Coeficientes do Modelo:**")
                    st.dataframe(results['coefficients'])
                    st.info(
                        f"""
                        **InterpretaÃ§Ã£o dos Coeficientes:** 
                        
                        Cada coeficiente (Î²) representa o quanto a variÃ¡vel dependente ({dependent_var}) 
                        muda, em mÃ©dia, para cada aumento de **uma unidade** na variÃ¡vel independente correspondente, 
                        **mantendo todas as outras variÃ¡veis constantes** (ceteris paribus).
                        
                        **Exemplo:** Se o coeficiente de 'FG%' for 2.5, significa que para cada aumento de 1% 
                        na porcentagem de arremessos convertidos, espera-se um aumento de 2.5 pontos em {dependent_var}.
                        """
                    )

                    # --- SeÃ§Ã£o de GrÃ¡ficos ---
                    st.subheader("VisualizaÃ§Ãµes GrÃ¡ficas")

                    # GrÃ¡fico 1: Diagrama de DispersÃ£o com Linha de RegressÃ£o
                    st.markdown("#### 1. Diagrama de DispersÃ£o com Linha de RegressÃ£o")
                    st.pyplot(plot_regression_scatter(
                        y_test=results['y_test'],
                        y_pred=results['y_pred'],
                        x_test_col=results['X_test'].iloc[:, 0],
                        x_label=independent_vars[0],
                        y_label=dependent_var
                    ))
                    st.caption(f"Este grÃ¡fico mostra a relaÃ§Ã£o entre a variÃ¡vel dependente ({dependent_var}) e a primeira variÃ¡vel independente selecionada ({independent_vars[0]}), com a linha de regressÃ£o ajustada pelo modelo.")

                    # GrÃ¡fico 2: PrevisÃ£o vs. Realidade
                    st.markdown("#### 2. GrÃ¡fico de PrevisÃ£o vs. Realidade")
                    st.pyplot(plot_predicted_vs_actual(
                        y_test=results['y_test'],
                        y_pred=results['y_pred'],
                        y_label=dependent_var
                    ))
                    st.caption("Este grÃ¡fico compara os valores reais com os valores previstos pelo modelo. Pontos prÃ³ximos Ã  linha tracejada vermelha indicam prediÃ§Ãµes precisas.")

                    # GrÃ¡fico 3: GrÃ¡fico de TendÃªncia com Intervalo de ConfianÃ§a
                    st.markdown("#### 3. GrÃ¡fico de TendÃªncia com Intervalo de ConfianÃ§a de 95%")
                    st.pyplot(plot_regression_confidence_interval(
                        df=df,
                        x_var=independent_vars,
                        y_var=dependent_var
                    ))
                    st.caption(f"Visualiza a tendÃªncia entre {dependent_var} e {independent_vars}. A Ã¡rea sombreada representa o intervalo de confianÃ§a de 95% para a linha de regressÃ£o, indicando a incerteza da estimativa.")

                    # GrÃ¡fico 4: Matriz de ConfusÃ£o (Adaptada)
                    st.markdown("#### 4. Matriz de ConfusÃ£o (Adaptada para RegressÃ£o)")
                    st.pyplot(plot_regression_confusion_matrix(
                        y_test=results['y_test'],
                        y_pred=results['y_pred']
                    ))
                    st.caption("Como a matriz de confusÃ£o Ã© para modelos de classificaÃ§Ã£o, adaptamos a anÃ¡lise: os valores foram classificados como 'Acima da MÃ©dia' ou 'Abaixo da MÃ©dia' para avaliar a capacidade do modelo de prever a magnitude do resultado.")

    # ============================================================================
    # ABA 2: EXPLORAÃ‡ÃƒO DE DADOS
    # ============================================================================
    with tabs[1]:
        st.subheader("ExploraÃ§Ã£o e AnÃ¡lise ExploratÃ³ria de Dados")

        # EstatÃ­sticas Descritivas
        st.markdown("#### ðŸ“Š EstatÃ­sticas Descritivas")
        stats_df = df[numeric_cols].describe().T
        stats_df["IQR"] = stats_df["75%"] - stats_df["25%"]
        st.dataframe(stats_df)

        # DistribuiÃ§Ã£o das VariÃ¡veis
        st.markdown("#### ðŸ“ˆ DistribuiÃ§Ã£o das VariÃ¡veis")
        fig, axes = plt.subplots(nrows=(len(numeric_cols) + 3) // 4, ncols=4, figsize=(16, 3 * ((len(numeric_cols) + 3) // 4)))
        fig.suptitle('DistribuiÃ§Ã£o das VariÃ¡veis', fontsize=16, fontweight='bold')

        for ax, column in zip(axes.flatten(), numeric_cols):
            sns.histplot(df[column], kde=True, ax=ax, color='skyblue', bins=30)
            ax.set_title(column, fontsize=12, fontweight='bold')
            ax.set_xlabel('')
            ax.set_ylabel('')

        plt.tight_layout(rect=[0, 0.03, 1, 0.95])
        st.pyplot(fig)

        # Matriz de CorrelaÃ§Ã£o
        st.markdown("#### ðŸ”— CorrelaÃ§Ãµes entre VariÃ¡veis")
        correlation_matrix = df[numeric_cols].corr()
        
        fig, ax = plt.subplots(figsize=(12, 10))
        sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', linewidths=.5, ax=ax)
        ax.set_title('Mapa de Calor da CorrelaÃ§Ã£o entre VariÃ¡veis', fontsize=14, fontweight='bold')
        st.pyplot(fig)

    # ============================================================================
    # ABA 3: ANÃLISE DE RESÃDUOS
    # ============================================================================
    with tabs[2]:
        st.subheader("ðŸŽ AnÃ¡lise de ResÃ­duos - ValidaÃ§Ã£o das Premissas")
        st.markdown("""
        A anÃ¡lise de resÃ­duos valida as premissas fundamentais da regressÃ£o linear:
        1. **Linearidade**: RelaÃ§Ã£o linear entre X e y
        2. **Homocedasticidade**: VariÃ¢ncia constante dos erros
        3. **Normalidade**: ResÃ­duos seguem distribuiÃ§Ã£o normal
        4. **IndependÃªncia**: AusÃªncia de padrÃµes nos resÃ­duos
        
        **ResÃ­duos**: DiferenÃ§as entre valores reais e preditos: $e_i = y_i - \\hat{y}_i$
        """)

        col1, col2 = st.columns(2)
        with col1:
            dependent_var_res = st.selectbox(
                "Escolha a VariÃ¡vel Dependente (Y):",
                options=numeric_cols,
                index=numeric_cols.index('PTS') if 'PTS' in numeric_cols else 0,
                key="res_dependent"
            )

        available_independent_vars_res = [v for v in numeric_cols if v != dependent_var_res]

        with col2:
            independent_vars_res = st.multiselect(
                "Escolha as VariÃ¡veis Independentes (X):",
                options=available_independent_vars_res,
                default=[available_independent_vars_res[0]] if available_independent_vars_res else [],
                key="res_independent"
            )

        if st.button("Gerar AnÃ¡lise de ResÃ­duos", type="primary", key="residuals_btn"):
            if not independent_vars_res:
                st.warning("Selecione pelo menos uma variÃ¡vel independente.")
            else:
                with st.spinner("Gerando anÃ¡lise de resÃ­duos..."):
                    results_res = train_linear_regression(df, independent_vars_res, dependent_var_res)
                    
                    residuals = results_res['y_test'] - results_res['y_pred']
                    standardized_residuals = (residuals - np.mean(residuals)) / np.std(residuals)

                    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
                    fig.suptitle('AnÃ¡lise de ResÃ­duos - ValidaÃ§Ã£o das Premissas da RegressÃ£o Linear', 
                                fontsize=14, fontweight='bold', y=1.00)

                    # 1. ResÃ­duos vs Valores Preditos
                    axes[0, 0].scatter(results_res['y_pred'], residuals, alpha=0.5, edgecolors='k', linewidth=0.5, s=30)
                    axes[0, 0].axhline(y=0, color='r', linestyle='--', linewidth=2, label='ResÃ­duo = 0')
                    axes[0, 0].set_xlabel('Valores Preditos', fontsize=12, fontweight='bold')
                    axes[0, 0].set_ylabel('ResÃ­duos', fontsize=12, fontweight='bold')
                    axes[0, 0].set_title('1. ResÃ­duos vs PrediÃ§Ãµes\nâœ“ PadrÃ£o aleatÃ³rio indica homocedasticidade', fontsize=12, fontweight='bold')
                    axes[0, 0].legend()
                    axes[0, 0].grid(True, alpha=0.3)

                    # 2. Histograma dos ResÃ­duos
                    axes[0, 1].hist(residuals, bins=50, density=True, alpha=0.7, color='skyblue', edgecolor='black', label='ResÃ­duos')
                    axes[0, 1].axvline(x=0, color='r', linestyle='--', linewidth=2, label='MÃ©dia = 0')
                    mu, sigma = residuals.mean(), residuals.std()
                    x = np.linspace(residuals.min(), residuals.max(), 100)
                    axes[0, 1].plot(x, stats.norm.pdf(x, mu, sigma), 'r-', linewidth=2, label=f'Normal(Î¼={mu:.2f}, Ïƒ={sigma:.2f})')
                    axes[0, 1].set_xlabel('ResÃ­duos', fontsize=12, fontweight='bold')
                    axes[0, 1].set_ylabel('Densidade', fontsize=12, fontweight='bold')
                    axes[0, 1].set_title('2. DistribuiÃ§Ã£o dos ResÃ­duos\nâœ“ Deve seguir distribuiÃ§Ã£o normal', fontsize=12, fontweight='bold')
                    axes[0, 1].legend()
                    axes[0, 1].grid(True, alpha=0.3)

                    # 3. Q-Q Plot
                    stats.probplot(residuals, dist="norm", plot=axes[1, 0])
                    axes[1, 0].get_lines()[0].set_markerfacecolor('blue')
                    axes[1, 0].get_lines()[0].set_markeredgecolor('black')
                    axes[1, 0].get_lines()[0].set_markersize(5)
                    axes[1, 0].get_lines()[1].set_color('red')
                    axes[1, 0].get_lines()[1].set_linewidth(2)
                    axes[1, 0].set_title('3. Q-Q Plot\nâœ“ Pontos na linha diagonal indicam normalidade', fontsize=12, fontweight='bold')
                    axes[1, 0].grid(True, alpha=0.3)

                    # 4. Scale-Location Plot
                    axes[1, 1].scatter(results_res['y_pred'], np.abs(standardized_residuals), alpha=0.5, edgecolors='k', linewidth=0.5, s=30)
                    axes[1, 1].axhline(y=2, color='orange', linestyle=':', linewidth=2, label='Â±2Ïƒ (95%)')
                    axes[1, 1].axhline(y=3, color='red', linestyle=':', linewidth=2, label='Â±3Ïƒ (99.7%)')
                    axes[1, 1].set_xlabel('Valores Preditos', fontsize=12, fontweight='bold')
                    axes[1, 1].set_ylabel('|ResÃ­duos Padronizados|', fontsize=12, fontweight='bold')
                    axes[1, 1].set_title('4. Scale-Location Plot\nâœ“ Linha horizontal indica variÃ¢ncia constante', fontsize=12, fontweight='bold')
                    axes[1, 1].legend(loc='upper right')
                    axes[1, 1].grid(True, alpha=0.3)

                    plt.tight_layout()
                    st.pyplot(fig)

                    # EstatÃ­sticas dos resÃ­duos
                    st.markdown("#### ðŸ“Š EstatÃ­sticas dos ResÃ­duos")
                    col1, col2, col3, col4 = st.columns(4)
                    col1.metric("MÃ©dia", f"{np.mean(residuals):.6f}")
                    col2.metric("Desvio PadrÃ£o", f"{np.std(residuals):.4f}")
                    col3.metric("MÃ­nimo", f"{np.min(residuals):.4f}")
                    col4.metric("MÃ¡ximo", f"{np.max(residuals):.4f}")

                    # Teste de Normalidade
                    st.markdown("#### ðŸ”¬ Teste de Normalidade (Shapiro-Wilk)")
                    sample_size = min(5000, len(residuals))
                    sample_residuals = np.random.choice(residuals, sample_size, replace=False)
                    statistic, p_value = stats.shapiro(sample_residuals)

                    col1, col2 = st.columns(2)
                    col1.metric("EstatÃ­stica W", f"{statistic:.6f}")
                    col2.metric("p-valor", f"{p_value:.6f}")

                    if p_value > 0.05:
                        st.success("âœ“ ResÃ­duos sÃ£o normais (p > 0.05)")
                    else:
                        st.warning("âœ— HÃ¡ desvios da normalidade (p â‰¤ 0.05)")

                    # DetecÃ§Ã£o de Outliers
                    st.markdown("#### âš ï¸ DetecÃ§Ã£o de Outliers")
                    outliers_2sigma = np.sum(np.abs(standardized_residuals) > 2)
                    outliers_3sigma = np.sum(np.abs(standardized_residuals) > 3)
                    total = len(residuals)

                    col1, col2, col3 = st.columns(3)
                    col1.metric("Total de observaÃ§Ãµes", total)
                    col2.metric("AlÃ©m de Â±2Ïƒ", f"{outliers_2sigma} ({outliers_2sigma/total*100:.2f}%)")
                    col3.metric("AlÃ©m de Â±3Ïƒ", f"{outliers_3sigma} ({outliers_3sigma/total*100:.2f}%)")